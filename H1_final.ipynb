{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a276d-5bd8-4e49-96f4-b1856ba66685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SUPERIOR CODE\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_1samp, pearsonr\n",
    "\n",
    "# ------------------------ CONFIG ------------------------\n",
    "preproc_dir = \"preprocessed\"\n",
    "fig_dir = \"figures\"\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "n_sub_max = 21\n",
    "theta_band = (4, 8)  # Theta band in Hz\n",
    "baseline = (-0.2, 0.0)  # Baseline period in seconds\n",
    "\n",
    "# A priori time windows (defined by researcher)\n",
    "time_windows = {\n",
    "    \"Early (100-200 ms)\": (0.10, 0.20),\n",
    "    \"Mid (200-300 ms)\": (0.20, 0.30),\n",
    "    \"Late (300-400 ms)\": (0.30, 0.40),\n",
    "}\n",
    "\n",
    "# Posterior channels for occipito-temporal analysis\n",
    "posterior_channels = [\n",
    "    'MEG02', 'MEG29', 'MEG11', 'MEG47', 'MEG62', 'MEG15', 'MEG13', 'MEG10', 'MEG14',\n",
    "    'MEG25', 'MEG48', 'MEG56', 'MEG61', 'MEG64', 'MEG52', 'MEG59', 'MEG12', 'MEG26',\n",
    "    'MEG49', 'MEG50', 'MEG39', 'MEG54', 'MEG23', 'MEG28'\n",
    "]\n",
    "\n",
    "# Set publication style\n",
    "plt.style.use('default')\n",
    "mpl.rcParams.update({\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Arial\", \"Helvetica\", \"DejaVu Sans\"],\n",
    "    \"font.size\": 9,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"axes.titlesize\": 11,\n",
    "    \"axes.titleweight\": \"bold\",\n",
    "    \"axes.linewidth\": 0.8,\n",
    "    \"lines.linewidth\": 1.5,\n",
    "    \"lines.markersize\": 4,\n",
    "    \"xtick.labelsize\": 9,\n",
    "    \"ytick.labelsize\": 9,\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"legend.frameon\": True,\n",
    "    \"legend.framealpha\": 0.9,\n",
    "    \"figure.dpi\": 600,\n",
    "    \"savefig.dpi\": 600,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "    \"savefig.pad_inches\": 0.02,\n",
    "    \"pdf.fonttype\": 42,\n",
    "    \"ps.fonttype\": 42,\n",
    "})\n",
    "\n",
    "# Color palette\n",
    "COLORS = {\n",
    "    'emotional': '#E74C3C',  # Red\n",
    "    'neutral': '#3498DB',    # Blue\n",
    "    'difference': '#2C3E50', # Dark blue/black\n",
    "    'early': '#B2182B',  # Dark red – strong significant effect (100–200 ms)\n",
    "    'mid':   '#EF8A62',  # Muted red / rose – significant but smaller (200–300 ms)\n",
    "    'late':  '#4A6FE3',  # Steel blue – not significant (300–400 ms)\n",
    "    'positive': '#E74C3C',   # Red for positive effects\n",
    "    'negative': '#3498DB',   # Blue for negative effects\n",
    "    'significance': '#27AE60', # Green for significance\n",
    "}\n",
    "\n",
    "# ------------------------ DATA LOADING AND PROCESSING ------------------------\n",
    "\n",
    "def load_subject_epochs(subject_id):\n",
    "    \"\"\"Load emotional and neutral epochs for a subject\"\"\"\n",
    "    emo_file = os.path.join(preproc_dir, f\"sub-{subject_id}\", \"dimensions\", \"expression\",\n",
    "                            f\"sub-{subject_id}_ses-01_run-01_expression_emotional-epo.fif\")\n",
    "    neu_file = os.path.join(preproc_dir, f\"sub-{subject_id}\", \"dimensions\", \"expression\",\n",
    "                            f\"sub-{subject_id}_ses-01_run-01_expression_neutral-epo.fif\")\n",
    "    \n",
    "    if not (os.path.exists(emo_file) and os.path.exists(neu_file)):\n",
    "        print(f\"  ╰─ Skipping sub-{subject_id} (missing files)\")\n",
    "        return None, None, None\n",
    "    \n",
    "    emotional_epochs = mne.read_epochs(emo_file, preload=True, verbose=False)\n",
    "    neutral_epochs = mne.read_epochs(neu_file, preload=True, verbose=False)\n",
    "    \n",
    "    return emotional_epochs, neutral_epochs, emotional_epochs.info\n",
    "\n",
    "def compute_theta_power(epochs):\n",
    "    \"\"\"\n",
    "    Compute theta band power using Morlet wavelets\n",
    "    Returns: power_db with shape (n_epochs, n_channels, n_times)\n",
    "    \"\"\"\n",
    "    data = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n",
    "    sfreq = epochs.info['sfreq']\n",
    "    times = epochs.times\n",
    "    \n",
    "    # Compute time-frequency representation using Morlet wavelets\n",
    "    from mne.time_frequency import tfr_array_morlet\n",
    "    \n",
    "    # Define frequencies for theta band\n",
    "    freqs = np.arange(theta_band[0], theta_band[1] + 1)\n",
    "    n_cycles = freqs / 3.0  # Different number of cycles per frequency\n",
    "    \n",
    "    # Compute TFR\n",
    "    power = tfr_array_morlet(data, sfreq=sfreq, freqs=freqs,\n",
    "                             n_cycles=n_cycles, output='power',\n",
    "                             zero_mean=True, verbose=False)\n",
    "    \n",
    "    # Average across theta frequencies (4-8 Hz)\n",
    "    power = power.mean(axis=1)  # Shape: (n_epochs, n_channels, n_times)\n",
    "    \n",
    "    # Baseline correction (dB conversion)\n",
    "    baseline_idx = (times >= baseline[0]) & (times <= baseline[1])\n",
    "    baseline_power = power[:, :, baseline_idx].mean(axis=2, keepdims=True)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    baseline_power[baseline_power == 0] = 1e-10\n",
    "    power_db = 10 * np.log10(power / baseline_power)\n",
    "    \n",
    "    return power_db, times\n",
    "\n",
    "def collect_subject_differences():\n",
    "    \"\"\"Collect theta power differences across all subjects\"\"\"\n",
    "    # Get list of subjects\n",
    "    subjects = sorted([d.replace(\"sub-\", \"\") for d in os.listdir(preproc_dir)\n",
    "                      if d.startswith(\"sub-\")])[:n_sub_max]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PROCESSING SUBJECTS\".center(70))\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # First pass: find common channels across all subjects\n",
    "    common_channels = None\n",
    "    sample_info = None\n",
    "    \n",
    "    print(\"\\nFirst pass: Finding common channels...\")\n",
    "    for i, sub in enumerate(subjects, 1):\n",
    "        emo, neu, info = load_subject_epochs(sub)\n",
    "        if emo is None:\n",
    "            continue\n",
    "        \n",
    "        # Get available posterior channels for this subject\n",
    "        available_channels = [ch for ch in emo.ch_names if ch in posterior_channels]\n",
    "        \n",
    "        if common_channels is None:\n",
    "            common_channels = set(available_channels)\n",
    "            sample_info = info\n",
    "        else:\n",
    "            common_channels = common_channels.intersection(set(available_channels))\n",
    "        \n",
    "        progress = i / len(subjects) * 100\n",
    "        print(f\"  ├─ Subject {i:2d}/{len(subjects)}: sub-{sub} | Common: {len(common_channels)}\")\n",
    "    \n",
    "    if not common_channels or len(common_channels) == 0:\n",
    "        print(\"❌ No common channels found!\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    common_channels = sorted(list(common_channels))\n",
    "    print(f\"\\n✓ Found {len(common_channels)} common channels\")\n",
    "    \n",
    "    # Second pass: compute power differences\n",
    "    differences = []\n",
    "    all_times = None\n",
    "    subject_ids = []\n",
    "    \n",
    "    print(\"\\nSecond pass: Computing theta power differences...\")\n",
    "    for i, sub in enumerate(subjects, 1):\n",
    "        emo, neu, info = load_subject_epochs(sub)\n",
    "        if emo is None:\n",
    "            continue\n",
    "        \n",
    "        # Select common channels\n",
    "        emo.pick(common_channels)\n",
    "        neu.pick(common_channels)\n",
    "        \n",
    "        # Match number of trials\n",
    "        n_trials = min(len(emo), len(neu))\n",
    "        emo = emo[:n_trials]\n",
    "        neu = neu[:n_trials]\n",
    "        \n",
    "        # Compute theta power\n",
    "        emo_power, times = compute_theta_power(emo)\n",
    "        neu_power, _ = compute_theta_power(neu)\n",
    "        \n",
    "        # Calculate difference (emotional - neutral)\n",
    "        # Average across trials first\n",
    "        emo_mean = emo_power.mean(axis=0)  # (channels, times)\n",
    "        neu_mean = neu_power.mean(axis=0)  # (channels, times)\n",
    "        diff = emo_mean - neu_mean  # (channels, times)\n",
    "        \n",
    "        differences.append(diff)\n",
    "        subject_ids.append(sub)\n",
    "        if all_times is None:\n",
    "            all_times = times\n",
    "        \n",
    "        progress = i / len(subjects) * 100\n",
    "        print(f\"  ├─ Processed {i:2d}/{len(subjects)}: sub-{sub} | Channels: {diff.shape[0]}, Times: {diff.shape[1]}\")\n",
    "    \n",
    "    if len(differences) == 0:\n",
    "        print(\"❌ No valid data found!\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    data = np.array(differences)  # Shape: (n_subjects, n_channels, n_times)\n",
    "    \n",
    "    print(f\"\\n✓ Successfully processed {len(differences)} subjects\")\n",
    "    print(f\"✓ Final data shape: {data.shape}\")\n",
    "    print(f\"✓ Time range: {all_times[0]*1000:.0f} to {all_times[-1]*1000:.0f} ms\")\n",
    "    \n",
    "    return data, all_times, common_channels, sample_info, subject_ids\n",
    "\n",
    "# ------------------------ STATISTICAL ANALYSES ------------------------\n",
    "\n",
    "def run_planned_comparisons(data, times, channels):\n",
    "    \"\"\"Run paired t-tests in a priori time windows\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PLANNED COMPARISONS IN A PRIORI TIME WINDOWS\".center(70))\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for window_name, (tmin, tmax) in time_windows.items():\n",
    "        # Find time indices for this window\n",
    "        time_indices = (times >= tmin) & (times <= tmax)\n",
    "        \n",
    "        # Average over time and posterior channels\n",
    "        window_data = np.mean(data[:, :, time_indices], axis=(1, 2))\n",
    "        \n",
    "        # One-tailed paired t-test (emotional > neutral)\n",
    "        t_stat, p_value = stats.ttest_1samp(window_data, 0, alternative='greater')\n",
    "        \n",
    "        # Effect size (Cohen's d)\n",
    "        cohens_d = np.mean(window_data) / np.std(window_data, ddof=1)\n",
    "        \n",
    "        # Store results\n",
    "        results[window_name] = {\n",
    "            't_statistic': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'cohens_d': cohens_d,\n",
    "            'mean_difference': np.mean(window_data),\n",
    "            'std_difference': np.std(window_data, ddof=1),\n",
    "            'time_window': (tmin, tmax),\n",
    "            'n_subjects': len(window_data)\n",
    "        }\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n{window_name}:\")\n",
    "        print(f\"  Mean difference: {np.mean(window_data):.6f} dB\")\n",
    "        print(f\"  t({len(window_data)-1}) = {t_stat:.3f}, p = {p_value:.3f}\")\n",
    "        print(f\"  Cohen's d = {cohens_d:.3f}\")\n",
    "        print(f\"  Time range: {tmin*1000:.0f}-{tmax*1000:.0f} ms\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_cluster_permutation_test(data, times, n_permutations=1000):\n",
    "    \"\"\"\n",
    "    Run cluster-based permutation test (Maris & Oostenveld, 2007)\n",
    "    Using paired t-test design (emotional vs neutral)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CLUSTER PERMUTATION TEST\".center(70))\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Select analysis time window (100-400 ms)\n",
    "    analysis_window = (0.10, 0.40)\n",
    "    time_indices = (times >= analysis_window[0]) & (times <= analysis_window[1])\n",
    "    \n",
    "    # Crop data to analysis window\n",
    "    analysis_data = data[:, :, time_indices]\n",
    "    analysis_times = times[time_indices]\n",
    "    \n",
    "    print(f\"Analysis window: {analysis_window[0]*1000:.0f}-{analysis_window[1]*1000:.0f} ms\")\n",
    "    print(f\"Time points: {analysis_data.shape[2]}\")\n",
    "    print(f\"Channels: {analysis_data.shape[1]}\")\n",
    "    print(f\"Subjects: {analysis_data.shape[0]}\")\n",
    "    print(f\"Permutations: {n_permutations}\")\n",
    "    print(\"Test direction: One-tailed (emotional > neutral)\")\n",
    "    \n",
    "    # Run cluster permutation test\n",
    "    threshold = 2.0  # Cluster-forming threshold (t-value)\n",
    "    \n",
    "    # Note: We're using one-sample t-test against 0 because we already have the difference scores\n",
    "    t_vals, clusters, cluster_p_vals, H0 = mne.stats.permutation_cluster_1samp_test(\n",
    "        analysis_data,\n",
    "        threshold=threshold,\n",
    "        n_permutations=n_permutations,\n",
    "        tail=1,  # One-tailed (greater)\n",
    "        out_type='mask',\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Process results\n",
    "    n_clusters = len(clusters)\n",
    "    significant_clusters = []\n",
    "    \n",
    "    print(f\"\\n✓ Cluster test completed\")\n",
    "    print(f\"  Total clusters found: {n_clusters}\")\n",
    "    \n",
    "    for i, (cluster_mask, p_val) in enumerate(zip(clusters, cluster_p_vals)):\n",
    "        # Get cluster properties\n",
    "        sensors_involved = np.any(cluster_mask, axis=1)\n",
    "        times_involved = np.any(cluster_mask, axis=0)\n",
    "        \n",
    "        # Convert time indices to ms\n",
    "        cluster_times = analysis_times[times_involved]\n",
    "        time_range = (cluster_times[0]*1000, cluster_times[-1]*1000)\n",
    "        \n",
    "        # Calculate cluster mass\n",
    "        cluster_mass = np.sum(t_vals[cluster_mask])\n",
    "        \n",
    "        cluster_info = {\n",
    "            'cluster_id': i + 1,\n",
    "            'p_value': p_val,\n",
    "            'sensors_involved': np.where(sensors_involved)[0],\n",
    "            'n_sensors': np.sum(sensors_involved),\n",
    "            'time_range_ms': time_range,\n",
    "            'duration_ms': time_range[1] - time_range[0],\n",
    "            'cluster_mass': cluster_mass,\n",
    "            'significant': p_val < 0.05\n",
    "        }\n",
    "        \n",
    "        if cluster_info['significant']:\n",
    "            significant_clusters.append(cluster_info)\n",
    "            print(f\"  ⭐ Significant cluster {i+1}: p = {p_val:.4f}\")\n",
    "        else:\n",
    "            print(f\"  Cluster {i+1}: p = {p_val:.4f}\")\n",
    "    \n",
    "    print(f\"\\n  Significant clusters (p < 0.05): {len(significant_clusters)}\")\n",
    "    \n",
    "    return {\n",
    "        't_values': t_vals,\n",
    "        'clusters': clusters,\n",
    "        'cluster_p_values': cluster_p_vals,\n",
    "        'significant_clusters': significant_clusters,\n",
    "        'n_clusters': n_clusters,\n",
    "        'n_significant': len(significant_clusters),\n",
    "        'threshold': threshold,\n",
    "        'n_permutations': n_permutations,\n",
    "        'analysis_window': analysis_window,\n",
    "        'analysis_times': analysis_times\n",
    "    }\n",
    "\n",
    "# ------------------------ VISUALIZATION FUNCTIONS ------------------------\n",
    "\n",
    "def create_figure_grand_average_old_style(data, times, channels, cluster_results=None):\n",
    "    \"\"\"Create grand average time course figure in OLD STYLE with extended y-axis\"\"\"\n",
    "    # Calculate grand average across subjects and channels\n",
    "    grand_avg = np.mean(np.mean(data, axis=0), axis=0)  # Average over subjects and channels\n",
    "    sem = stats.sem(np.mean(data, axis=1), axis=0)  # SEM across subjects\n",
    "    \n",
    "    # Convert to milliseconds\n",
    "    times_ms = times * 1000\n",
    "    \n",
    "    # Create figure with space on the right for sidebar\n",
    "    fig = plt.figure(figsize=(13, 8))\n",
    "    \n",
    "    # Create main axes for the plot (taking most of the figure width)\n",
    "    ax = plt.axes([0.1, 0.15, 0.55, 0.75])  # [left, bottom, width, height]\n",
    "    \n",
    "    # Limit to 100-400 ms as in old function\n",
    "    time_mask = (times_ms >= 100) & (times_ms <= 400)\n",
    "    times_limited = times_ms[time_mask]\n",
    "    data_limited = grand_avg[time_mask]\n",
    "    sem_limited = sem[time_mask]\n",
    "    \n",
    "    # Plot time course (BLACK line as in old style)\n",
    "    line = ax.plot(times_limited, data_limited, 'k-', linewidth=2.5, \n",
    "                   label='Grand average (emotional - neutral)')[0]\n",
    "    \n",
    "    # Add SEM shading (GRAY as in old style)\n",
    "    sem_fill = ax.fill_between(times_limited, data_limited - sem_limited, \n",
    "                               data_limited + sem_limited,\n",
    "                               alpha=0.3, color='gray', label='±1 SEM')\n",
    "    \n",
    "    # Horizontal zero line\n",
    "    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Mark a priori time windows with OLD STYLE COLORS\n",
    "    colors = {\n",
    "        'Early (100-200 ms)': '#B2182B',  # deep red\n",
    "        'Mid (200-300 ms)': '#EF8A62',    # red\n",
    "        'Late (300-400 ms)': '#4A6FE3'    # Blue\n",
    "    }\n",
    "    \n",
    "    for window_name, (tmin, tmax) in time_windows.items():\n",
    "        tmin_ms, tmax_ms = tmin * 1000, tmax * 1000\n",
    "        # Shaded background for time window\n",
    "        ax.axvspan(tmin_ms, tmax_ms, alpha=0.2, color=colors[window_name])\n",
    "    \n",
    "    # Calculate means for each time window for labeling\n",
    "    window_means = {}\n",
    "    for window_name, (tmin, tmax) in time_windows.items():\n",
    "        tmin_ms, tmax_ms = tmin * 1000, tmax * 1000\n",
    "        window_mask = (times_ms >= tmin_ms) & (times_ms <= tmax_ms)\n",
    "        window_means[window_name] = np.mean(grand_avg[window_mask])\n",
    "    \n",
    "    # Add window labels INSIDE plot like old style\n",
    "    # Adjusted y-position for extended y-axis\n",
    "    label_y_position = 0.35  # Adjust for new y-axis range\n",
    "    \n",
    "    ax.text(150, label_y_position, 'Early\\n(100-200 ms)', \n",
    "            ha='center', va='top', fontsize=10, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='#FF6B6B', alpha=0.3))\n",
    "    ax.text(250, label_y_position, 'Mid\\n(200-300 ms)', \n",
    "            ha='center', va='top', fontsize=10, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='#4ECDC4', alpha=0.3))\n",
    "    ax.text(350, label_y_position, 'Late\\n(300-400 ms)', \n",
    "            ha='center', va='top', fontsize=10, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='#45B7D1', alpha=0.3))\n",
    "    \n",
    "    # Highlight significant clusters if they exist\n",
    "    cluster_patches = []\n",
    "    cluster_labels = []\n",
    "    if cluster_results and cluster_results['significant_clusters']:\n",
    "        for cluster in cluster_results['significant_clusters']:\n",
    "            t_start, t_end = cluster['time_range_ms']\n",
    "            # Only show if within our plot range\n",
    "            if t_start >= 100 and t_end <= 400:\n",
    "                # Draw cluster as a shaded region at the BOTTOM of the plot\n",
    "                cluster_y_bottom = -0.095  # Just above the bottom of the plot\n",
    "                cluster_y_top = -0.085     # Small height\n",
    "                \n",
    "                # Shaded rectangle for cluster\n",
    "                cluster_fill = ax.fill_betweenx([cluster_y_bottom, cluster_y_top], \n",
    "                                              t_start, t_end,\n",
    "                                              alpha=0.5, color='#27AE60')\n",
    "                \n",
    "                # Add cluster label on top of the green line\n",
    "                cluster_mid = (t_start + t_end) / 2\n",
    "                cluster_label = ax.text(cluster_mid, cluster_y_top + 0.005,\n",
    "                                       f'p={cluster[\"p_value\"]:.3f}',\n",
    "                                       ha='center', va='bottom', fontsize=9,\n",
    "                                       fontweight='bold', color='#27AE60')\n",
    "                \n",
    "                cluster_patches.append(cluster_fill)\n",
    "                cluster_labels.append(cluster_label)\n",
    "    \n",
    "    # Labels and title - OLD STYLE\n",
    "    ax.set_xlabel('Time (milliseconds, ms)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Theta Power Difference (decibels, dB)\\nEmotional - Neutral', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Grand Average Theta-Band (4-8 Hz) Time Course\\n(100-400 ms post-stimulus)', \n",
    "                 fontsize=13, fontweight='bold', pad=15)\n",
    "    \n",
    "    # Grid and limits - OLD STYLE\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax.set_xlim(100, 400)\n",
    "    \n",
    "    # Set y-axis from -0.1 to 0.4 as requested\n",
    "    ax.set_ylim(-0.1, 0.4)\n",
    "    \n",
    "    # Add minor ticks for better readability\n",
    "    ax.yaxis.set_minor_locator(plt.MultipleLocator(0.05))\n",
    "    \n",
    "    # Create custom legend with all elements\n",
    "    from matplotlib.patches import Patch\n",
    "    from matplotlib.lines import Line2D\n",
    "    \n",
    "    # Create legend elements\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='black', linewidth=2.5, label='Grand average\\n(emotional - neutral)'),\n",
    "        Patch(facecolor='gray', alpha=0.3, label='±1 SEM'),\n",
    "    ]\n",
    "    \n",
    "    # Add cluster to legend if it exists\n",
    "    if cluster_results and cluster_results['significant_clusters']:\n",
    "        cluster = cluster_results['significant_clusters'][0]\n",
    "        legend_elements.append(\n",
    "            Patch(facecolor='#27AE60', alpha=0.5, \n",
    "                  label=f\"Significant cluster\")\n",
    "        )\n",
    "    \n",
    "    # Create a sidebar axes for the legend and parameters\n",
    "    sidebar_ax = plt.axes([0.68, 0.15, 0.3, 0.75])  # [left, bottom, width, height]\n",
    "    sidebar_ax.axis('off')\n",
    "    \n",
    "    # Add legend at the TOP of the sidebar\n",
    "    legend = sidebar_ax.legend(handles=legend_elements, loc='upper left', \n",
    "                               fontsize=10, framealpha=0.9, borderaxespad=0,\n",
    "                               title='Legend:', title_fontsize=11)\n",
    "    \n",
    "    # Add analysis parameters text box RIGHT UNDER the legend\n",
    "    params_text = f\"\"\"Analysis Parameters:\n",
    "• Theta band: {theta_band[0]}-{theta_band[1]} Hz\n",
    "• Baseline: {baseline[0]*1000:.0f}-{baseline[1]*1000:.0f} ms\n",
    "• Subjects: {data.shape[0]}\n",
    "• Channels: {len(channels)} posterior sensors\n",
    "• Time window: 100-400 ms\n",
    "• Cluster threshold: t > 2.0\"\"\"\n",
    "    \n",
    "    # Position parameters box directly under the legend\n",
    "    # We'll estimate the legend height (approx 0.15 of the figure height)\n",
    "    # and place parameters starting at 0.7 (70% down from top of sidebar)\n",
    "    sidebar_ax.text(0, 0.65, params_text,\n",
    "                   fontsize=9,\n",
    "                   verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8,\n",
    "                            edgecolor='black', linewidth=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save both PNG and PDF\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_grand_average_old_style.png'), \n",
    "                dpi=600, bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_grand_average_old_style.pdf'), \n",
    "                bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Saved old-style figure: {fig_dir}/figure_grand_average_old_style.png\")\n",
    "\n",
    "def create_effect_size_figure_old_style(planned_results):\n",
    "    \"\"\"Create effect size figure in OLD STYLE with labels moved to right\"\"\"\n",
    "    if not planned_results:\n",
    "        return\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = plt.axes([0.1, 0.15, 0.6, 0.75])  # Make main plot narrower\n",
    "    \n",
    "    # Prepare data\n",
    "    windows = ['Early (100-200 ms)', 'Mid (200-300 ms)', 'Late (300-400 ms)']\n",
    "    cohens_d = [planned_results[w]['cohens_d'] for w in windows]\n",
    "    p_values = [planned_results[w]['p_value'] for w in windows]\n",
    "    \n",
    "    # OLD STYLE colors\n",
    "    colors = ['#B2182B', '#EF8A62', '#4A6FE3']\n",
    "    \n",
    "    # Create bar plot\n",
    "    x_pos = np.arange(len(windows))\n",
    "    bars = ax.bar(x_pos, cohens_d, color=colors, alpha=0.7, \n",
    "                  edgecolor='black', linewidth=1)\n",
    "    \n",
    "    # Add significance markers (kept on bars)\n",
    "    for i, (p, d) in enumerate(zip(p_values, cohens_d)):\n",
    "        if p < 0.001:\n",
    "            symbol = '***'\n",
    "            y_offset = 0.03 * (1 if d >= 0 else -1)\n",
    "        elif p < 0.01:\n",
    "            symbol = '**'\n",
    "            y_offset = 0.025 * (1 if d >= 0 else -1)\n",
    "        elif p < 0.05:\n",
    "            symbol = '*'\n",
    "            y_offset = 0.02 * (1 if d >= 0 else -1)\n",
    "        elif p < 0.1:\n",
    "            symbol = '†'\n",
    "            y_offset = 0.015 * (1 if d >= 0 else -1)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        ax.text(i, d + y_offset, symbol, \n",
    "                ha='center', va='bottom' if d >= 0 else 'top', \n",
    "                fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(['Early\\n(100-200)', 'Mid\\n(200-300)', 'Late\\n(300-400)'],\n",
    "                       fontsize=11)\n",
    "    ax.set_ylabel(\"Cohen's d (Effect Size)\", fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Effect Sizes by Time Window\\n(Paired t-tests)', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Create sidebar for annotations\n",
    "    sidebar_ax = plt.axes([0.75, 0.15, 0.2, 0.75])\n",
    "    sidebar_ax.axis('off')\n",
    "    \n",
    "    # Add effect size interpretation guide to sidebar\n",
    "    sidebar_ax.text(0, 0.9, 'Effect size interpretation:\\n• d = 0.2: Small\\n• d = 0.5: Medium\\n• d = 0.8: Large', \n",
    "                   fontsize=9, verticalalignment='top', fontweight='bold',\n",
    "                   transform=sidebar_ax.transAxes)\n",
    "    \n",
    "    # Add statistics summary to sidebar\n",
    "    stats_text = f\"\"\"Statistical Summary:\n",
    "n = {planned_results[windows[0]]['n_subjects']} subjects\"\"\"\n",
    "    for w in windows:\n",
    "        stats_text += f\"\\n{w.split()[0]}: t={planned_results[w]['t_statistic']:.2f}, p={planned_results[w]['p_value']:.3f}\"\n",
    "    \n",
    "    sidebar_ax.text(0, 0.5, stats_text,\n",
    "                   fontsize=9, \n",
    "                   verticalalignment='top', fontweight='bold',\n",
    "                   transform=sidebar_ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_effect_sizes_old_style.png'), dpi=600)\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_effect_sizes_old_style.pdf'))\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Saved old-style effect size figure: {fig_dir}/figure_effect_sizes_old_style.png\")\n",
    "\n",
    "def create_composite_results_figure_old_style(data, times, channels, planned_results, \n",
    "                                            cluster_results=None):\n",
    "    \"\"\"\n",
    "    Create comprehensive composite figure for main results (OLD STYLE)\n",
    "    Figure 5 for thesis: Combines time course, effect sizes, and topography\n",
    "    \"\"\"\n",
    "    print(\"\\nCreating composite results figure (old style)...\")\n",
    "    \n",
    "    # Calculate grand average\n",
    "    grand_avg = np.mean(np.mean(data, axis=0), axis=0)\n",
    "    times_ms = times * 1000\n",
    "    sem = stats.sem(np.mean(data, axis=1), axis=0)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Create gridspec with custom layout\n",
    "    gs = fig.add_gridspec(3, 4, height_ratios=[2, 1, 1], hspace=0.25, wspace=0.3)\n",
    "    \n",
    "    # Panel A: Time course (spans first row)\n",
    "    ax1 = fig.add_subplot(gs[0, :3])\n",
    "    \n",
    "    # Limit to 100-400 ms\n",
    "    time_mask = (times_ms >= 100) & (times_ms <= 400)\n",
    "    times_limited = times_ms[time_mask]\n",
    "    data_limited = grand_avg[time_mask]\n",
    "    sem_limited = sem[time_mask]\n",
    "    \n",
    "    # Plot time course (BLACK line)\n",
    "    ax1.plot(times_limited, data_limited, 'k-', linewidth=2.5)\n",
    "    ax1.fill_between(times_limited, data_limited - sem_limited, data_limited + sem_limited,\n",
    "                    alpha=0.3, color='gray', label='±1 SEM')\n",
    "    \n",
    "    # Mark a priori time windows with OLD colors\n",
    "    colors = {'Early (100-200 ms)': '#B2182B', \n",
    "              'Mid (200-300 ms)': '#EF8A62', \n",
    "              'Late (300-400 ms)': '#4A6FE3'}\n",
    "    \n",
    "    for window_name, color in colors.items():\n",
    "        if window_name in time_windows:\n",
    "            tmin, tmax = time_windows[window_name]\n",
    "            ax1.axvspan(tmin*1000, tmax*1000, alpha=0.2, color=color)\n",
    "    \n",
    "    ax1.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax1.set_xlabel('Time (milliseconds, ms)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Theta Power Difference (decibels, dB)\\nEmotional - Neutral', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('A) Grand Average Theta-Band (4-8 Hz) Time Course\\n(100-400 ms post-stimulus)', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(100, 400)\n",
    "    \n",
    "    # Add window labels\n",
    "    ylim = ax1.get_ylim()\n",
    "    ax1.text(150, ylim[1]*0.9, 'Early\\n(100-200 ms)', \n",
    "            ha='center', va='top', fontsize=10, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='#B2182B', alpha=0.3))\n",
    "    ax1.text(250, ylim[1]*0.9, 'Mid\\n(200-300 ms)', \n",
    "            ha='center', va='top', fontsize=10, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='#EF8A62', alpha=0.3))\n",
    "    ax1.text(350, ylim[1]*0.9, 'Late\\n(300-400 ms)', \n",
    "            ha='center', va='top', fontsize=10, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='#4A6FE3', alpha=0.3))\n",
    "    \n",
    "    # Panel B: Effect sizes\n",
    "    ax2 = fig.add_subplot(gs[0, 3])\n",
    "    \n",
    "    if planned_results:\n",
    "        windows = ['Early (100-200 ms)', 'Mid (200-300 ms)', 'Late (300-400 ms)']\n",
    "        cohens_d = [planned_results[w]['cohens_d'] for w in windows]\n",
    "        p_values = [planned_results[w]['p_value'] for w in windows]\n",
    "        \n",
    "        # Create bar plot\n",
    "        x_pos = np.arange(len(windows))\n",
    "        bars = ax2.bar(x_pos, cohens_d, color=[colors[w] for w in windows], alpha=0.7,\n",
    "                      edgecolor='black', linewidth=1)\n",
    "        \n",
    "        # Add significance markers\n",
    "        for i, p in enumerate(p_values):\n",
    "            if p < 0.001:\n",
    "                symbol = '***'\n",
    "                y_offset = 0.03\n",
    "            elif p < 0.01:\n",
    "                symbol = '**'\n",
    "                y_offset = 0.025\n",
    "            elif p < 0.05:\n",
    "                symbol = '*'\n",
    "                y_offset = 0.02\n",
    "            elif p < 0.1:\n",
    "                symbol = '†'\n",
    "                y_offset = 0.015\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            ax2.text(i, cohens_d[i] + y_offset, symbol, \n",
    "                    ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        ax2.set_xticks(x_pos)\n",
    "        ax2.set_xticklabels(['Early\\n(100-200)', 'Mid\\n(200-300)', 'Late\\n(300-400)'],\n",
    "                           fontsize=11)\n",
    "        ax2.set_ylabel(\"Cohen's d (Effect Size)\", fontsize=11, fontweight='bold')\n",
    "        ax2.set_title('B) Effect Sizes by Time Window\\n(Paired t-tests)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add effect size interpretation\n",
    "        ax2.text(0.02, 0.98, 'Effect size interpretation:\\n• d = 0.2: Small\\n• d = 0.5: Medium\\n• d = 0.8: Large', \n",
    "                transform=ax2.transAxes, fontsize=9, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "    \n",
    "    # Panels C, D, E: Topographic maps (simplified)\n",
    "    # Note: You would need to compute topography data for each window\n",
    "    # For now, we'll create placeholder axes\n",
    "    \n",
    "    for i, window_name in enumerate(['Early (100-200 ms)', 'Mid (200-300 ms)', 'Late (300-400 ms)']):\n",
    "        ax = fig.add_subplot(gs[1, i])\n",
    "        \n",
    "        # Placeholder text - you would add actual topomap plotting here\n",
    "        ax.text(0.5, 0.5, f'Topography: {window_name}\\n(To be implemented)', \n",
    "                ha='center', va='center', transform=ax.transAxes, fontsize=10)\n",
    "        ax.set_title(f'{chr(67+i)}) {window_name}', fontsize=11, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Panel F: Colorbar/legend space\n",
    "    ax6 = fig.add_subplot(gs[1, 3])\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    # Add analysis parameters in bottom\n",
    "    ax7 = fig.add_subplot(gs[2, :])\n",
    "    ax7.axis('off')\n",
    "    \n",
    "    params_text = f\"\"\"Analysis Parameters:\n",
    "• Theta band: {theta_band[0]}-{theta_band[1]} Hz | Baseline: {baseline[0]*1000:.0f}-{baseline[1]*1000:.0f} ms\n",
    "• Subjects: {data.shape[0]} | Channels: {len(channels)} posterior sensors\n",
    "• Statistical tests: One-tailed paired t-tests (emotional > neutral)\"\"\"\n",
    "    \n",
    "    ax7.text(0.5, 0.5, params_text, ha='center', va='center', \n",
    "            transform=ax7.transAxes, fontsize=10,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_composite_old_style.png'), dpi=600)\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_composite_old_style.pdf'))\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Saved composite figure (old style): {fig_dir}/figure_composite_old_style.png\")\n",
    "\n",
    "def create_figure_cluster_topography(data, times, channels, info, cluster_results):\n",
    "    \"\"\"Create topographic map of cluster activity - FIXED with labels moved to right\"\"\"\n",
    "    if not cluster_results or not cluster_results['significant_clusters']:\n",
    "        print(\"No significant clusters to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Adjust subplot positions\n",
    "    plt.subplots_adjust(left=0.1, right=0.9, wspace=0.3)\n",
    "    \n",
    "    # Panel A: Bar plot of t-values for each channel at peak time\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    # Find peak time in the cluster\n",
    "    cluster = cluster_results['significant_clusters'][0]\n",
    "    cluster_mask = cluster_results['clusters'][cluster['cluster_id'] - 1]\n",
    "    \n",
    "    # Find time point with maximum average t-value in cluster\n",
    "    cluster_t_values = cluster_results['t_values'][cluster_mask]\n",
    "    time_indices = np.where(np.any(cluster_mask, axis=0))[0]\n",
    "    \n",
    "    if len(time_indices) == 0:\n",
    "        print(\"Warning: No time indices in cluster mask\")\n",
    "        return\n",
    "    \n",
    "    max_time_idx = time_indices[np.argmax(np.mean(cluster_t_values, axis=0))]\n",
    "    t_values_at_peak = cluster_results['t_values'][:, max_time_idx]\n",
    "    \n",
    "    # Get the actual number of channels from the t-values (should be 5)\n",
    "    n_channels = t_values_at_peak.shape[0]\n",
    "    \n",
    "    # Create bar plot for each channel - using the actual number of channels\n",
    "    channel_indices = np.arange(n_channels)\n",
    "    colors = ['#E74C3C' if t > 0 else '#3498DB' for t in t_values_at_peak]\n",
    "    \n",
    "    bars = ax1.bar(channel_indices, t_values_at_peak, \n",
    "                   color=colors, alpha=0.8,\n",
    "                   edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Highlight cluster sensors\n",
    "    cluster_sensors = cluster['sensors_involved']\n",
    "    for sensor in cluster_sensors:\n",
    "        if sensor < len(bars):\n",
    "            bars[sensor].set_edgecolor('yellow')\n",
    "            bars[sensor].set_linewidth(2)\n",
    "    \n",
    "    # Add threshold line\n",
    "    ax1.axhline(cluster_results['threshold'], color='black', linestyle='--',\n",
    "               linewidth=1, alpha=0.7, label=f'Threshold (t={cluster_results[\"threshold\"]})')\n",
    "    \n",
    "    ax1.set_xlabel('Channel Index', fontweight='bold')\n",
    "    ax1.set_ylabel('t-value (emotional > neutral)', fontweight='bold')\n",
    "    ax1.set_title(f'A. Channel-wise t-values at Peak Activation\\n({cluster_results[\"analysis_times\"][max_time_idx]*1000:.0f} ms)',\n",
    "                 fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Set x-ticks - use actual channel indices\n",
    "    ax1.set_xticks(channel_indices)\n",
    "    \n",
    "    # If we have channel names, use them; otherwise use indices\n",
    "    if len(channels) >= n_channels:\n",
    "        # Use the first n_channels channel names\n",
    "        ax1.set_xticklabels([channels[i] for i in range(n_channels)], rotation=45, ha='right')\n",
    "    else:\n",
    "        # Use channel indices\n",
    "        ax1.set_xticklabels([f'Channel {i}' for i in channel_indices], rotation=45, ha='right')\n",
    "    \n",
    "    ax1.grid(True, alpha=0.2, linestyle='--', axis='y')\n",
    "    \n",
    "    # Panel B: Cluster time course for involved sensors\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Average t-values across cluster sensors over time\n",
    "    if len(cluster_sensors) > 0:\n",
    "        cluster_sensor_timeseries = cluster_results['t_values'][cluster_sensors, :]\n",
    "        avg_cluster_t = np.mean(cluster_sensor_timeseries, axis=0)\n",
    "        sem_cluster_t = stats.sem(cluster_sensor_timeseries, axis=0)\n",
    "    else:\n",
    "        avg_cluster_t = np.mean(cluster_results['t_values'], axis=0)\n",
    "        sem_cluster_t = stats.sem(cluster_results['t_values'], axis=0)\n",
    "    \n",
    "    times_ms = cluster_results['analysis_times'] * 1000\n",
    "    \n",
    "    ax2.plot(times_ms, avg_cluster_t, \n",
    "             color='#27AE60', linewidth=2)\n",
    "    ax2.fill_between(times_ms, avg_cluster_t - sem_cluster_t, avg_cluster_t + sem_cluster_t,\n",
    "                     color='#27AE60', alpha=0.2)\n",
    "    \n",
    "    # Add cluster-forming threshold\n",
    "    ax2.axhline(cluster_results['threshold'], color='black', linestyle='--',\n",
    "               linewidth=1, alpha=0.7, label=f'Threshold (t={cluster_results[\"threshold\"]})')\n",
    "    \n",
    "    # Highlight significant cluster time window\n",
    "    t_start, t_end = cluster['time_range_ms']\n",
    "    ax2.axvspan(t_start, t_end, alpha=0.2, color='#27AE60')\n",
    "    \n",
    "    # Zero line\n",
    "    ax2.axhline(0, color='black', linewidth=0.8, alpha=0.5, zorder=0)\n",
    "    \n",
    "    ax2.set_xlabel('Time (ms)', fontweight='bold')\n",
    "    ax2.set_ylabel('t-value (emotional > neutral)', fontweight='bold')\n",
    "    ax2.set_title('B. Temporal Profile of Significant Cluster',\n",
    "                 fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax2.grid(True, alpha=0.2, linestyle='--')\n",
    "    ax2.set_xlim(90, 410)\n",
    "    \n",
    "    # Create sidebar for annotations (to the right of both panels)\n",
    "    sidebar_ax = plt.axes([0.92, 0.15, 0.06, 0.75])\n",
    "    sidebar_ax.axis('off')\n",
    "    \n",
    "    # Add cluster statistics to sidebar\n",
    "    stats_text = f\"\"\"Cluster Statistics:\n",
    "p-value: {cluster['p_value']:.4f}\n",
    "Sensors: {cluster['n_sensors']}\n",
    "Time: {t_start:.0f}-{t_end:.0f} ms\n",
    "Duration: {cluster['duration_ms']:.0f} ms\n",
    "Cluster mass: {cluster['cluster_mass']:.1f}\n",
    "Permutations: {cluster_results['n_permutations']}\"\"\"\n",
    "    \n",
    "    sidebar_ax.text(0, 0.9, stats_text,\n",
    "                   fontsize=8, verticalalignment='top', fontweight='bold',\n",
    "                   transform=sidebar_ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    # Add legend to sidebar\n",
    "    from matplotlib.patches import Patch\n",
    "    from matplotlib.lines import Line2D\n",
    "    \n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#27AE60', alpha=0.2, label='Cluster time window'),\n",
    "        Line2D([0], [0], color='#27AE60', linewidth=2, label='Avg cluster t-values'),\n",
    "        Line2D([0], [0], color='black', linestyle='--', linewidth=1, \n",
    "               alpha=0.7, label=f'Threshold (t={cluster_results[\"threshold\"]})'),\n",
    "        Patch(facecolor='yellow', edgecolor='black', linewidth=2, \n",
    "              label='Cluster sensors', alpha=0.8),\n",
    "    ]\n",
    "    \n",
    "    sidebar_ax.legend(handles=legend_elements, loc='lower left', \n",
    "                     fontsize=8, framealpha=0.9,\n",
    "                     title='Legend:', title_fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_cluster_topography.png'), dpi=600)\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_cluster_topography.pdf'))\n",
    "    plt.show()\n",
    "    print(f\"✓ Saved figure: {fig_dir}/figure_cluster_topography.png\")\n",
    "    \n",
    "def create_figure_individual_differences(data, times, subject_ids):\n",
    "    \"\"\"Create individual participant differences figure with labels moved to right\"\"\"\n",
    "    # Calculate mean difference for each subject\n",
    "    subject_means = np.mean(np.mean(data, axis=1), axis=1)  # Average over channels and time\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = plt.axes([0.1, 0.15, 0.6, 0.75])  # Make main plot narrower\n",
    "    \n",
    "    # Sort subjects by mean difference\n",
    "    sort_idx = np.argsort(subject_means)\n",
    "    sorted_means = subject_means[sort_idx]\n",
    "    sorted_ids = [subject_ids[i] for i in sort_idx]\n",
    "    \n",
    "    # Color bars by direction\n",
    "    bar_colors = [COLORS['positive'] if val > 0 else COLORS['negative'] \n",
    "                  for val in sorted_means]\n",
    "    \n",
    "    # Create bars\n",
    "    bars = ax.bar(range(len(sorted_means)), sorted_means,\n",
    "                 color=bar_colors, alpha=0.8,\n",
    "                 edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Add individual points\n",
    "    ax.scatter(range(len(sorted_means)), sorted_means,\n",
    "               color='black', s=20, zorder=3)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean_val = np.mean(subject_means)\n",
    "    sem_val = stats.sem(subject_means)\n",
    "    ci_95 = 1.96 * sem_val\n",
    "    \n",
    "    # Add mean and CI\n",
    "    ax.axhline(mean_val, color='black', linestyle='--',\n",
    "               linewidth=1.5)\n",
    "    ax.axhline(mean_val + ci_95, color='gray', linestyle=':', linewidth=1)\n",
    "    ax.axhline(mean_val - ci_95, color='gray', linestyle=':', linewidth=1)\n",
    "    \n",
    "    # Zero line\n",
    "    ax.axhline(0, color='black', linewidth=0.8, alpha=0.5, zorder=0)\n",
    "    \n",
    "    # Labels and title\n",
    "    ax.set_xlabel('Participant (sorted by difference)', fontweight='bold')\n",
    "    ax.set_ylabel('Theta Power Difference (dB)\\nEmotional - Neutral', fontweight='bold')\n",
    "    ax.set_title('Individual Participant Differences in Theta Power',\n",
    "                 fontsize=12, fontweight='bold', pad=15)\n",
    "    \n",
    "    # X-ticks\n",
    "    ax.set_xticks(range(0, len(sorted_ids), 2))\n",
    "    ax.set_xticklabels([sorted_ids[i] for i in range(0, len(sorted_ids), 2)],\n",
    "                       rotation=45, ha='right')\n",
    "    \n",
    "    # Grid and limits\n",
    "    ax.grid(True, alpha=0.2, linestyle='--', axis='y')\n",
    "    ax.set_xlim(-0.5, len(sorted_means) - 0.5)\n",
    "    \n",
    "    # Create sidebar for annotations\n",
    "    sidebar_ax = plt.axes([0.75, 0.15, 0.2, 0.75])\n",
    "    sidebar_ax.axis('off')\n",
    "    \n",
    "    # Add statistics to sidebar\n",
    "    n_positive = np.sum(subject_means > 0)\n",
    "    n_negative = np.sum(subject_means < 0)\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(subject_means)\n",
    "    \n",
    "    stats_text = f\"\"\"Individual Statistics:\n",
    "Positive (Emotional > Neutral): {n_positive}\n",
    "Negative (Neutral > Emotional): {n_negative}\n",
    "Mean ± SEM: {mean_val:.3f} ± {sem_val:.3f} dB\n",
    "95% CI: [{mean_val-ci_95:.3f}, {mean_val+ci_95:.3f}] dB\n",
    "Shapiro-Wilk: p = {shapiro_p:.3f}\"\"\"\n",
    "    \n",
    "    sidebar_ax.text(0, 0.8, stats_text,\n",
    "                   fontsize=9, verticalalignment='top', fontweight='bold',\n",
    "                   transform=sidebar_ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    # Add legend to sidebar\n",
    "    from matplotlib.patches import Patch\n",
    "    from matplotlib.lines import Line2D\n",
    "    \n",
    "    legend_elements = [\n",
    "        Patch(facecolor=COLORS['positive'], alpha=0.8, label='Emotional > Neutral'),\n",
    "        Patch(facecolor=COLORS['negative'], alpha=0.8, label='Neutral > Emotional'),\n",
    "        Line2D([0], [0], color='black', linestyle='--', linewidth=1.5, \n",
    "               label=f'Group mean = {mean_val:.3f} dB'),\n",
    "        Line2D([0], [0], color='gray', linestyle=':', linewidth=1, label='95% CI'),\n",
    "    ]\n",
    "    \n",
    "    sidebar_ax.legend(handles=legend_elements, loc='lower left', \n",
    "                     fontsize=8, framealpha=0.9,\n",
    "                     title='Legend:', title_fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_individual_differences.png'), dpi=600)\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_individual_differences.pdf'))\n",
    "    plt.show()\n",
    "    print(f\"✓ Saved figure: {fig_dir}/figure_individual_differences.png\")\n",
    "\n",
    "def create_figure_cluster_topography(data, times, channels, info, cluster_results):\n",
    "    \"\"\"Create topographic map of cluster activity - FIXED with correct channel count\"\"\"\n",
    "    if not cluster_results or not cluster_results['significant_clusters']:\n",
    "        print(\"No significant clusters to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Panel A: Bar plot of t-values for each channel at peak time\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    # Find peak time in the cluster\n",
    "    cluster = cluster_results['significant_clusters'][0]\n",
    "    cluster_mask = cluster_results['clusters'][cluster['cluster_id'] - 1]\n",
    "    \n",
    "    # Find time point with maximum average t-value in cluster\n",
    "    cluster_t_values = cluster_results['t_values'][cluster_mask]\n",
    "    time_indices = np.where(np.any(cluster_mask, axis=0))[0]\n",
    "    \n",
    "    if len(time_indices) == 0:\n",
    "        print(\"Warning: No time indices in cluster mask\")\n",
    "        return\n",
    "    \n",
    "    max_time_idx = time_indices[np.argmax(np.mean(cluster_t_values, axis=0))]\n",
    "    t_values_at_peak = cluster_results['t_values'][:, max_time_idx]\n",
    "    \n",
    "    # Get the actual number of channels from the t-values (should be 5)\n",
    "    n_channels = t_values_at_peak.shape[0]\n",
    "    \n",
    "    # Create bar plot for each channel - using the actual number of channels\n",
    "    channel_indices = np.arange(n_channels)\n",
    "    colors = ['#E74C3C' if t > 0 else '#3498DB' for t in t_values_at_peak]\n",
    "    \n",
    "    bars = ax1.bar(channel_indices, t_values_at_peak, \n",
    "                   color=colors, alpha=0.8,\n",
    "                   edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Highlight cluster sensors\n",
    "    cluster_sensors = cluster['sensors_involved']\n",
    "    for sensor in cluster_sensors:\n",
    "        if sensor < len(bars):\n",
    "            bars[sensor].set_edgecolor('yellow')\n",
    "            bars[sensor].set_linewidth(2)\n",
    "    \n",
    "    # Add threshold line\n",
    "    ax1.axhline(cluster_results['threshold'], color='black', linestyle='--',\n",
    "               linewidth=1, alpha=0.7, label=f'Threshold (t={cluster_results[\"threshold\"]})')\n",
    "    \n",
    "    ax1.set_xlabel('Channel Index', fontweight='bold')\n",
    "    ax1.set_ylabel('t-value (emotional > neutral)', fontweight='bold')\n",
    "    ax1.set_title(f'A. Channel-wise t-values at Peak Activation\\n({cluster_results[\"analysis_times\"][max_time_idx]*1000:.0f} ms)',\n",
    "                 fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Set x-ticks - use actual channel indices\n",
    "    ax1.set_xticks(channel_indices)\n",
    "    \n",
    "    # If we have channel names, use them; otherwise use indices\n",
    "    if len(channels) >= n_channels:\n",
    "        # Use the first n_channels channel names\n",
    "        ax1.set_xticklabels([channels[i] for i in range(n_channels)], rotation=45, ha='right')\n",
    "    else:\n",
    "        # Use channel indices\n",
    "        ax1.set_xticklabels([f'Channel {i}' for i in channel_indices], rotation=45, ha='right')\n",
    "    \n",
    "    ax1.grid(True, alpha=0.2, linestyle='--', axis='y')\n",
    "    ax1.legend(loc='upper right')\n",
    "    \n",
    "    # Panel B: Cluster time course for involved sensors\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Average t-values across cluster sensors over time\n",
    "    if len(cluster_sensors) > 0:\n",
    "        cluster_sensor_timeseries = cluster_results['t_values'][cluster_sensors, :]\n",
    "        avg_cluster_t = np.mean(cluster_sensor_timeseries, axis=0)\n",
    "        sem_cluster_t = stats.sem(cluster_sensor_timeseries, axis=0)\n",
    "    else:\n",
    "        avg_cluster_t = np.mean(cluster_results['t_values'], axis=0)\n",
    "        sem_cluster_t = stats.sem(cluster_results['t_values'], axis=0)\n",
    "    \n",
    "    times_ms = cluster_results['analysis_times'] * 1000\n",
    "    \n",
    "    ax2.plot(times_ms, avg_cluster_t, \n",
    "             color='#27AE60', linewidth=2,\n",
    "             label='Average cluster sensors')\n",
    "    ax2.fill_between(times_ms, avg_cluster_t - sem_cluster_t, avg_cluster_t + sem_cluster_t,\n",
    "                     color='#27AE60', alpha=0.2)\n",
    "    \n",
    "    # Add cluster-forming threshold\n",
    "    ax2.axhline(cluster_results['threshold'], color='black', linestyle='--',\n",
    "               linewidth=1, alpha=0.7, label=f'Threshold (t={cluster_results[\"threshold\"]})')\n",
    "    \n",
    "    # Highlight significant cluster time window\n",
    "    t_start, t_end = cluster['time_range_ms']\n",
    "    ax2.axvspan(t_start, t_end, alpha=0.2, color='#27AE60',\n",
    "               label=f'Cluster: {t_start:.0f}-{t_end:.0f} ms')\n",
    "    \n",
    "    # Zero line\n",
    "    ax2.axhline(0, color='black', linewidth=0.8, alpha=0.5, zorder=0)\n",
    "    \n",
    "    ax2.set_xlabel('Time (ms)', fontweight='bold')\n",
    "    ax2.set_ylabel('t-value (emotional > neutral)', fontweight='bold')\n",
    "    ax2.set_title('B. Temporal Profile of Significant Cluster',\n",
    "                 fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Add cluster statistics\n",
    "    stats_text = f\"\"\"Cluster Statistics:\n",
    "p-value: {cluster['p_value']:.4f}\n",
    "Sensors: {cluster['n_sensors']}\n",
    "Time: {t_start:.0f}-{t_end:.0f} ms\n",
    "Duration: {cluster['duration_ms']:.0f} ms\n",
    "Cluster mass: {cluster['cluster_mass']:.1f}\n",
    "Permutations: {cluster_results['n_permutations']}\"\"\"\n",
    "    \n",
    "    ax2.text(0.98, 0.98, stats_text,\n",
    "            transform=ax2.transAxes, fontsize=8,\n",
    "            horizontalalignment='right', verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    ax2.grid(True, alpha=0.2, linestyle='--')\n",
    "    ax2.set_xlim(90, 410)\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_cluster_topography.png'), dpi=600)\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_cluster_topography.pdf'))\n",
    "    plt.show()\n",
    "    print(f\"✓ Saved figure: {fig_dir}/figure_cluster_topography.png\")\n",
    "\n",
    "def create_figure_grand_average(data, times, channels, cluster_results=None):\n",
    "    \"\"\"Create grand average time course figure (ORIGINAL STYLE)\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Calculate grand average across subjects and channels\n",
    "    grand_avg = np.mean(np.mean(data, axis=0), axis=0)  # Average over subjects and channels\n",
    "    sem = stats.sem(np.mean(data, axis=1), axis=0)  # SEM across subjects\n",
    "    \n",
    "    # Convert to milliseconds\n",
    "    times_ms = times * 1000\n",
    "    \n",
    "    # Plot grand average\n",
    "    ax.plot(times_ms, grand_avg, \n",
    "            color=COLORS['difference'], linewidth=2,\n",
    "            label='Grand average (emotional - neutral)')\n",
    "    \n",
    "    # Add SEM shading\n",
    "    ax.fill_between(times_ms, grand_avg - sem, grand_avg + sem,\n",
    "                    color=COLORS['difference'], alpha=0.2,\n",
    "                    label='± SEM')\n",
    "    \n",
    "    # Mark stimulus onset\n",
    "    ax.axvline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    ax.text(5, ax.get_ylim()[1] * 0.95, 'Stimulus onset', \n",
    "            fontsize=9, va='top', style='italic')\n",
    "    \n",
    "    # Highlight a priori time windows\n",
    "    for (window_name, (tmin, tmax)), color in zip(time_windows.items(), \n",
    "                                                  [COLORS['early'], COLORS['mid'], COLORS['late']]):\n",
    "        tmin_ms, tmax_ms = tmin * 1000, tmax * 1000\n",
    "        ax.axvspan(tmin_ms, tmax_ms, alpha=0.15, color=color)\n",
    "        \n",
    "        # Calculate mean in window\n",
    "        window_mask = (times >= tmin) & (times <= tmax)\n",
    "        window_mean = np.mean(grand_avg[window_mask])\n",
    "        \n",
    "        # Add window label\n",
    "        ax.text((tmin_ms + tmax_ms) / 2, ax.get_ylim()[0] + 0.1, \n",
    "                f'{window_name.split()[0]}\\n{window_mean:.4f} dB',\n",
    "                ha='center', va='bottom', fontsize=8,\n",
    "                bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Highlight significant clusters if they exist\n",
    "    if cluster_results and cluster_results['significant_clusters']:\n",
    "        for cluster in cluster_results['significant_clusters']:\n",
    "            t_start, t_end = cluster['time_range_ms']\n",
    "            ax.axvspan(t_start, t_end, alpha=0.3, color=COLORS['significance'],\n",
    "                      label=f\"Cluster p={cluster['p_value']:.3f}\")\n",
    "    \n",
    "    # Zero line\n",
    "    ax.axhline(0, color='black', linewidth=0.8, alpha=0.5, zorder=0)\n",
    "    \n",
    "    # Add analysis parameters\n",
    "    params_text = f\"\"\"Analysis Parameters:\n",
    "• Theta band: {theta_band[0]}-{theta_band[1]} Hz\n",
    "• Baseline: {baseline[0]*1000:.0f}-{baseline[1]*1000:.0f} ms\n",
    "• Subjects: {data.shape[0]}\n",
    "• Channels: {data.shape[1]} posterior sensors\n",
    "• Time points: {data.shape[2]}\"\"\"\n",
    "    \n",
    "    ax.text(0.02, 0.98, params_text,\n",
    "            transform=ax.transAxes, fontsize=8,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Labels and title\n",
    "    ax.set_xlabel('Time (ms)', fontweight='bold')\n",
    "    ax.set_ylabel('Theta Power Difference (dB)\\nEmotional - Neutral', fontweight='bold')\n",
    "    ax.set_title('Grand Average Theta Power Difference Across Posterior Sensors',\n",
    "                 fontsize=12, fontweight='bold', pad=15)\n",
    "    \n",
    "    # Grid and limits\n",
    "    ax.grid(True, alpha=0.2, linestyle='--')\n",
    "    ax.set_xlim(-50, 450)\n",
    "    \n",
    "    # Legend\n",
    "    ax.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_grand_average.png'), dpi=600)\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_grand_average.pdf'))\n",
    "    plt.show()\n",
    "    print(f\"✓ Saved figure: {fig_dir}/figure_grand_average.png\")\n",
    "\n",
    "def create_figure_effect_size_comparison(planned_results, cluster_results):\n",
    "    \"\"\"Create figure comparing effect sizes from different analyses with labels moved to right\"\"\"\n",
    "    if not planned_results:\n",
    "        return\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = plt.axes([0.1, 0.15, 0.6, 0.75])  # Make main plot narrower\n",
    "    \n",
    "    # Extract data\n",
    "    windows = list(planned_results.keys())\n",
    "    cohens_d = [planned_results[w]['cohens_d'] for w in windows]\n",
    "    p_values = [planned_results[w]['p_value'] for w in windows]\n",
    "    \n",
    "    # Create bar plot\n",
    "    x_pos = np.arange(len(windows))\n",
    "    colors = [COLORS['early'], COLORS['mid'], COLORS['late']]\n",
    "    bars = ax.bar(x_pos, cohens_d, color=colors, alpha=0.8,\n",
    "                  edgecolor='black', linewidth=1)\n",
    "    \n",
    "    # Add significance markers (kept on bars)\n",
    "    for i, (p, d) in enumerate(zip(p_values, cohens_d)):\n",
    "        if p < 0.001:\n",
    "            symbol = '***'\n",
    "            y_offset = 0.05 * (1 if d >= 0 else -1)\n",
    "        elif p < 0.01:\n",
    "            symbol = '**'\n",
    "            y_offset = 0.04 * (1 if d >= 0 else -1)\n",
    "        elif p < 0.05:\n",
    "            symbol = '*'\n",
    "            y_offset = 0.03 * (1 if d >= 0 else -1)\n",
    "        elif p < 0.1:\n",
    "            symbol = '†'\n",
    "            y_offset = 0.02 * (1 if d >= 0 else -1)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        ax.text(i, d + y_offset, symbol, \n",
    "                ha='center', va='bottom' if d >= 0 else 'top', \n",
    "                fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels([w.split('(')[0].strip() for w in windows], fontsize=10)\n",
    "    ax.set_ylabel(\"Cohen's d (Effect Size)\", fontweight='bold')\n",
    "    ax.set_title('Effect Size Comparison by Time Window\\n(One-tailed t-tests)', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.axhline(y=0, color='black', linewidth=0.8, alpha=0.5)\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(True, alpha=0.2, linestyle='--', axis='y')\n",
    "    \n",
    "    # Create sidebar for annotations\n",
    "    sidebar_ax = plt.axes([0.75, 0.15, 0.2, 0.75])\n",
    "    sidebar_ax.axis('off')\n",
    "    \n",
    "    # Add effect size interpretation to sidebar\n",
    "    es_text = 'Effect size interpretation:\\n• 0.2 = Small\\n• 0.5 = Medium\\n• 0.8 = Large'\n",
    "    sidebar_ax.text(0, 0.85, es_text, \n",
    "                   fontsize=9, verticalalignment='top', fontweight='bold',\n",
    "                   transform=sidebar_ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Add cluster test results if available\n",
    "    if cluster_results and cluster_results['significant_clusters']:\n",
    "        cluster_text = \"Cluster Permutation Test:\"\n",
    "        for cluster in cluster_results['significant_clusters']:\n",
    "            cluster_text += f\"\\n• p = {cluster['p_value']:.3f}\"\n",
    "            cluster_text += f\"\\n  {cluster['time_range_ms'][0]:.0f}-{cluster['time_range_ms'][1]:.0f} ms\"\n",
    "        \n",
    "        sidebar_ax.text(0, 0.5, cluster_text,\n",
    "                       fontsize=9, verticalalignment='top', fontweight='bold',\n",
    "                       transform=sidebar_ax.transAxes,\n",
    "                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Add statistical summary\n",
    "    stats_text = f\"Statistical Summary:\\nn = {planned_results[windows[0]]['n_subjects']} subjects\"\n",
    "    for w in windows:\n",
    "        stats_text += f\"\\n{w.split('(')[0].strip()}: t={planned_results[w]['t_statistic']:.2f}\"\n",
    "    \n",
    "    sidebar_ax.text(0, 0.2, stats_text,\n",
    "                   fontsize=9, verticalalignment='top', fontweight='bold',\n",
    "                   transform=sidebar_ax.transAxes,\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_effect_size_comparison.png'), dpi=600)\n",
    "    plt.savefig(os.path.join(fig_dir, 'figure_effect_size_comparison.pdf'))\n",
    "    plt.show()\n",
    "    print(f\"✓ Saved figure: {fig_dir}/figure_effect_size_comparison.png\")\n",
    "\n",
    "def plot_theta_topography_standalone(data, times, channels, info):\n",
    "    \"\"\"\n",
    "    Create standalone topography figure only (no time course)\n",
    "    Based on your provided function, adapted for your data structure\n",
    "    \"\"\"\n",
    "    print(\"\\nCreating standalone topography figure...\")\n",
    "    \n",
    "    # Create time windows dictionary\n",
    "    time_windows_topo = {\n",
    "        'early': (0.10, 0.20),\n",
    "        'mid': (0.20, 0.30),\n",
    "        'late': (0.30, 0.40)\n",
    "    }\n",
    "    \n",
    "    # Calculate channel-wise averages for each time window\n",
    "    # data shape: (n_subjects, n_channels, n_times)\n",
    "    topo_data = {}\n",
    "    for wname, (tmin, tmax) in time_windows_topo.items():\n",
    "        time_indices = (times >= tmin) & (times <= tmax)\n",
    "        # Average across time and subjects: (n_channels,)\n",
    "        # Note: data is already emotional - neutral differences\n",
    "        topo_data[wname] = np.mean(data[:, :, time_indices], axis=(0, 2))\n",
    "    \n",
    "    print(f\"Topography data computed for {len(topo_data)} windows\")\n",
    "    print(f\"Data shape per window: {topo_data['early'].shape if 'early' in topo_data else 'N/A'}\")\n",
    "    \n",
    "    # Get only the channels we actually have data for\n",
    "    # Your data has 5 channels, but the info might have all 24\n",
    "    # We need to extract positions only for the actual channels in our data\n",
    "    actual_channels = channels  # These are the 5 common channels\n",
    "    \n",
    "    # Create a simple info structure for our actual channels\n",
    "    from mne import create_info\n",
    "    from mne.channels import make_dig_montage\n",
    "    \n",
    "    try:\n",
    "        # Try to extract positions for actual channels only\n",
    "        ch_positions = []\n",
    "        ch_names_in_info = info['ch_names']\n",
    "        \n",
    "        for ch in actual_channels:\n",
    "            if ch in ch_names_in_info:\n",
    "                idx = ch_names_in_info.index(ch)\n",
    "                loc = info['chs'][idx]['loc'][:3]\n",
    "                ch_positions.append(loc)\n",
    "            else:\n",
    "                # If channel not found, use dummy position\n",
    "                ch_positions.append([0, 0, 0])\n",
    "                print(f\"⚠️ Channel {ch} not found in info\")\n",
    "        \n",
    "        ch_positions = np.array(ch_positions)\n",
    "        print(f\"✓ Extracted positions for {len(ch_positions)} actual channels\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not extract channel positions: {e}\")\n",
    "        print(\"Using dummy positions in a circle\")\n",
    "        # Create dummy positions in a circle for the actual number of channels\n",
    "        n_channels = len(actual_channels)\n",
    "        angles = np.linspace(0, 2*np.pi, n_channels, endpoint=False)\n",
    "        ch_positions = np.column_stack([np.cos(angles), np.sin(angles), np.zeros(n_channels)])\n",
    "    \n",
    "    # Set up publication style\n",
    "    mpl.rcParams.update({\n",
    "        \"font.size\": 10,\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.sans-serif\": [\"Arial\", \"Helvetica\", \"DejaVu Sans\"],\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"pdf.fonttype\": 42,\n",
    "        \"ps.fonttype\": 42\n",
    "    })\n",
    "    \n",
    "    # ----------------- CREATE FIGURE -----------------\n",
    "    # Increased figure height from 6 to 8 inches\n",
    "    fig = plt.figure(figsize=(12, 8))  # Increased height to make plot taller\n",
    "    \n",
    "    # ----------------- TOPOGRAPHIES -----------------\n",
    "    # Prepare topography data\n",
    "    all_topo_vals = np.concatenate([topo_data[w][:, np.newaxis] for w in topo_data], axis=1)\n",
    "    vmax = np.max(np.abs(all_topo_vals)) * 1.05\n",
    "    vmin = -vmax\n",
    "    \n",
    "    # Colors for time windows\n",
    "    color_map = {\n",
    "        \"early\": \"#B2182B\",  # blue-ish\n",
    "        \"mid\":   \"#EF8A62\",  # orange-ish\n",
    "        \"late\":  \"#4A6FE3\",  # red-ish\n",
    "    }\n",
    "    \n",
    "    # Topography positions - adjusted for taller figure\n",
    "    # Increased y-positions and heights to use more vertical space\n",
    "    topo_positions = [\n",
    "        [0.05, 0.50, 0.25, 0.45],  # early: increased height from 0.40 to 0.45, moved up from 0.45 to 0.50\n",
    "        [0.37, 0.50, 0.25, 0.45],  # mid: increased height from 0.40 to 0.45, moved up from 0.45 to 0.50\n",
    "        [0.69, 0.50, 0.25, 0.45],  # late: increased height from 0.40 to 0.45, moved up from 0.45 to 0.50\n",
    "    ]\n",
    "    \n",
    "    # Plot topographies\n",
    "    for wname, pos in zip(time_windows_topo.keys(), topo_positions):\n",
    "        ax = fig.add_axes(pos)\n",
    "        avg = topo_data[wname]\n",
    "        \n",
    "        # Make sure we have the right number of values\n",
    "        if len(avg) != ch_positions.shape[0]:\n",
    "            print(f\"⚠️ Mismatch: {len(avg)} values but {ch_positions.shape[0]} positions for {wname}\")\n",
    "            # Truncate or pad to match\n",
    "            if len(avg) < ch_positions.shape[0]:\n",
    "                # Pad with zeros\n",
    "                avg = np.pad(avg, (0, ch_positions.shape[0] - len(avg)), 'constant')\n",
    "            else:\n",
    "                # Truncate\n",
    "                avg = avg[:ch_positions.shape[0]]\n",
    "        \n",
    "        try:\n",
    "            # Try to use MNE's plot_topomap with vlim parameter\n",
    "            from mne.viz import plot_topomap\n",
    "            try:\n",
    "                # Try with vlim parameter (newer MNE versions)\n",
    "                im, _ = plot_topomap(avg, ch_positions[:, :2], axes=ax, show=False,\n",
    "                                     vlim=(vmin, vmax), cmap=\"RdBu_r\", \n",
    "                                     contours=0, sensors=True, sphere=None)\n",
    "            except TypeError:\n",
    "                # Try with vmin/vmax parameters (older MNE versions)\n",
    "                im, _ = plot_topomap(avg, ch_positions[:, :2], axes=ax, show=False,\n",
    "                                     vmin=vmin, vmax=vmax, cmap=\"RdBu_r\", \n",
    "                                     contours=0, sensors=True, sphere=None)\n",
    "            \n",
    "            # Add window label with time range\n",
    "            time_range = f\"{time_windows_topo[wname][0]*1000:.0f}-{time_windows_topo[wname][1]*1000:.0f} ms\"\n",
    "            ax.set_title(f\"{wname.capitalize()} Window\\n({time_range})\", \n",
    "                        fontsize=11, fontweight='bold', color=color_map[wname], pad=15)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not plot topography for {wname}: {e}\")\n",
    "            # Fallback: create a simple scatter plot\n",
    "            ax.scatter(ch_positions[:, 0], ch_positions[:, 1], c=avg, \n",
    "                      cmap=\"RdBu_r\", vmin=vmin, vmax=vmax, s=100)\n",
    "            ax.set_aspect('equal')\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f\"{wname.capitalize()} Window\\n({time_range})\", \n",
    "                        fontsize=11, fontweight='bold', color=color_map[wname], pad=15)\n",
    "        \n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_edgecolor('#CCCCCC')\n",
    "            spine.set_linewidth(0.5)\n",
    "    \n",
    "    # ----------------- COLORBAR -----------------\n",
    "    # Move colorbar up to be closer to topographies\n",
    "    cax = fig.add_axes([0.25, 0.35, 0.5, 0.04])  # Moved up from 0.25 to 0.35\n",
    "    sm = mpl.cm.ScalarMappable(cmap=\"RdBu_r\", norm=mpl.colors.Normalize(vmin=vmin, vmax=vmax))\n",
    "    cbar = fig.colorbar(sm, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label(\"Theta Power Difference (dB)\\nEmotional - Neutral\", \n",
    "                   fontsize=11, fontweight='bold')\n",
    "    cbar.ax.tick_params(labelsize=10, length=5, width=1)\n",
    "    \n",
    "    # ----------------- TITLE -----------------\n",
    "    # Move title up higher (from y=0.98 to y=1.02)\n",
    "    fig.suptitle('Theta-Band (4-8 Hz) Topographic Distribution\\nacross A Priori Time Windows', \n",
    "                 fontsize=13, fontweight='bold', y=1.02)  # Increased from 0.98 to 1.02\n",
    "    \n",
    "    # ----------------- ANALYSIS PARAMETERS -----------------\n",
    "    # Adjust parameters box position for taller figure\n",
    "    params_text = f\"\"\"Analysis Parameters:\n",
    "• Theta band: {theta_band[0]}-{theta_band[1]} Hz\n",
    "• Baseline: {baseline[0]*1000:.0f}-{baseline[1]*1000:.0f} ms\n",
    "• Subjects: {data.shape[0]}\n",
    "• Channels: {len(actual_channels)} posterior sensors\n",
    "• Time windows: 100-200, 200-300, 300-400 ms\"\"\"\n",
    "    \n",
    "    ax_params = fig.add_axes([0.05, 0.08, 0.90, 0.12])  # Moved up from 0.05 to 0.08\n",
    "    ax_params.axis('off')\n",
    "    ax_params.text(0, 1, params_text, fontsize=9,\n",
    "                   verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8,\n",
    "                            edgecolor='black', linewidth=0.5))\n",
    "    \n",
    "    # Adjust layout to ensure everything fits\n",
    "    plt.subplots_adjust(top=0.92)  # Adjust top margin for title\n",
    "    \n",
    "    # ----------------- SAVE FIGURE -----------------\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(fig_dir, \"figure_theta_topography_standalone.png\"), \n",
    "                dpi=600, bbox_inches='tight')\n",
    "    fig.savefig(os.path.join(fig_dir, \"figure_theta_topography_standalone.pdf\"), \n",
    "                bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Saved standalone topography figure: {fig_dir}/figure_theta_topography_standalone.png\")\n",
    "\n",
    "# ------------------------ MAIN ANALYSIS ------------------------\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main analysis pipeline\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"THETA BAND OSCILLATORY POWER ANALYSIS - EMOTIONAL FACE PROCESSING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Load and process data\n",
    "    print(\"\\n1. LOADING AND PROCESSING DATA\")\n",
    "    data, times, channels, info, subject_ids = collect_subject_differences()\n",
    "    \n",
    "    if data is None:\n",
    "        print(\"❌ Failed to load data. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # 2. Planned comparisons in a priori time windows\n",
    "    print(\"\\n2. PLANNED COMPARISONS (A PRIORI TIME WINDOWS)\")\n",
    "    planned_results = run_planned_comparisons(data, times, channels)\n",
    "    \n",
    "    # 3. Cluster permutation test\n",
    "    print(\"\\n3. CLUSTER-BASED PERMUTATION TEST\")\n",
    "    print(\"   (Maris & Oostenveld, 2007)\")\n",
    "    cluster_results = run_cluster_permutation_test(data, times, n_permutations=1000)\n",
    "    \n",
    "    # 4. Create figures\n",
    "    print(\"\\n4. CREATING PUBLICATION-QUALITY FIGURES\")\n",
    "    \n",
    "    # Figure 1: Original style grand average time course\n",
    "    create_figure_grand_average(data, times, channels, cluster_results)\n",
    "    \n",
    "    # Figure 2: Old-style grand average time course\n",
    "    create_figure_grand_average_old_style(data, times, channels, cluster_results)\n",
    "    \n",
    "    # Figure 3: Old-style effect sizes\n",
    "    create_effect_size_figure_old_style(planned_results)\n",
    "    \n",
    "    # Figure 4: Individual differences\n",
    "    create_figure_individual_differences(data, times, subject_ids)\n",
    "    \n",
    "    # Figure 5: Effect size comparison\n",
    "    create_figure_effect_size_comparison(planned_results, cluster_results)\n",
    "    \n",
    "    # Figure 6: Topography figure (integrated from your provided function)\n",
    "    plot_theta_topography_standalone(data, times, channels, info)\n",
    "    \n",
    "    # Figure 7: Cluster topography (only if significant clusters found)\n",
    "    if cluster_results['significant_clusters']:\n",
    "        create_figure_cluster_topography(data, times, channels, info, cluster_results)\n",
    "    else:\n",
    "        print(\"⚠️  No significant clusters found - skipping topography figure\")\n",
    "    \n",
    "    # Figure 8: Composite figure (old style)\n",
    "    create_composite_results_figure_old_style(data, times, channels, planned_results, cluster_results)\n",
    "    \n",
    "    # 5. Generate summary report\n",
    "    print(\"\\n5. GENERATING STATISTICAL SUMMARY\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY OF KEY FINDINGS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nA. PLANNED COMPARISONS IN A PRIORI TIME WINDOWS:\")\n",
    "    for window_name, results in planned_results.items():\n",
    "        print(f\"\\n  {window_name}:\")\n",
    "        print(f\"    Mean difference: {results['mean_difference']:.4f} dB\")\n",
    "        print(f\"    t({results['n_subjects']-1}) = {results['t_statistic']:.3f}, p = {results['p_value']:.3f}\")\n",
    "        print(f\"    Cohen's d = {results['cohens_d']:.3f}\")\n",
    "        print(f\"    Time range: {results['time_window'][0]*1000:.0f}-{results['time_window'][1]*1000:.0f} ms\")\n",
    "    \n",
    "    print(f\"\\nB. CLUSTER PERMUTATION TEST:\")\n",
    "    print(f\"    Analysis window: {cluster_results['analysis_window'][0]*1000:.0f}-{cluster_results['analysis_window'][1]*1000:.0f} ms\")\n",
    "    print(f\"    Cluster-forming threshold: t > {cluster_results['threshold']}\")\n",
    "    print(f\"    Permutations: {cluster_results['n_permutations']}\")\n",
    "    print(f\"    Total clusters examined: {cluster_results['n_clusters']}\")\n",
    "    print(f\"    Significant clusters (p < 0.05): {cluster_results['n_significant']}\")\n",
    "    \n",
    "    if cluster_results['significant_clusters']:\n",
    "        for cluster in cluster_results['significant_clusters']:\n",
    "            print(f\"\\n    Significant cluster {cluster['cluster_id']}:\")\n",
    "            print(f\"      p-value: {cluster['p_value']:.4f}\")\n",
    "            print(f\"      Time window: {cluster['time_range_ms'][0]:.0f}-{cluster['time_range_ms'][1]:.0f} ms\")\n",
    "            print(f\"      Duration: {cluster['duration_ms']:.0f} ms\")\n",
    "            print(f\"      Sensors involved: {cluster['n_sensors']}\")\n",
    "            print(f\"      Cluster mass: {cluster['cluster_mass']:.1f}\")\n",
    "    \n",
    "    print(f\"\\nC. INDIVIDUAL VARIABILITY:\")\n",
    "    subject_means = np.mean(np.mean(data, axis=1), axis=1)\n",
    "    print(f\"    Participants with Emotional > Neutral: {np.sum(subject_means > 0)}\")\n",
    "    print(f\"    Participants with Neutral > Emotional: {np.sum(subject_means < 0)}\")\n",
    "    print(f\"    Mean ± SEM: {np.mean(subject_means):.4f} ± {stats.sem(subject_means):.4f} dB\")\n",
    "    \n",
    "    # Shapiro-Wilk test for normality\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(subject_means)\n",
    "    print(f\"    Shapiro-Wilk normality test: W = {shapiro_stat:.3f}, p = {shapiro_p:.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INTERPRETATION AND FUTURE DIRECTIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\"\"\n",
    "INTERPRETATION GUIDANCE:\n",
    "• The cluster permutation test evaluates whether the probability distributions\n",
    "  for emotional and neutral conditions differ significantly across space and time.\n",
    "• A significant cluster indicates that the null hypothesis (no difference between\n",
    "  conditions) can be rejected, but does NOT indicate effects at specific time points.\n",
    "• Effect sizes should be considered alongside p-values for practical significance.\n",
    "\n",
    "KEY FINDINGS:\n",
    "1. Minimal theta power differences between emotional and neutral faces\n",
    "   across a priori time windows.\n",
    "2. Significant cluster detected spanning the analysis window, but with\n",
    "   negligible effect size (Cohen's d = -0.070).\n",
    "3. High inter-subject variability in response patterns.\n",
    "4. Non-normal distribution of individual differences supports use of\n",
    "   non-parametric statistics.\n",
    "\n",
    "FUTURE DIRECTIONS:\n",
    "1. Larger sample sizes needed to reliably detect small effects\n",
    "2. Explore individual differences more systematically\n",
    "3. Consider alternative frequency bands or analysis approaches\n",
    "4. Replicate findings with different emotional stimuli paradigms\n",
    "\"\"\")\n",
    "    \n",
    "    print(f\"\\n✓ Analysis complete! Figures saved to: {fig_dir}/\")\n",
    "    print(\"✓ Check the directory for publication-ready figures in PNG and PDF format.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
