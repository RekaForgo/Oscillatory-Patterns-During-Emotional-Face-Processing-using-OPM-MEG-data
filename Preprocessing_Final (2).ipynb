{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a9a517-a0e3-44a0-aecd-170025573438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# FINAL WORKING PREPROCESSING SCRIPT\n",
    "# ================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def extract_image_number(filename):\n",
    "    \"\"\"Extract image number from filename\"\"\"\n",
    "    if isinstance(filename, str):\n",
    "        match = re.search(r'(\\d+)\\.bmp', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def create_stimulus_mapping():\n",
    "    \"\"\"Create mapping for all 64 images with 4 dimensions based on actual stimulus descriptions\"\"\"\n",
    "    mapping = {}\n",
    "    \n",
    "    # Groups of 8 images each follow this pattern:\n",
    "    # First 4: neutral, Last 4: emotional\n",
    "    # 8 groups total, ordered by: race-gender-age\n",
    "    \n",
    "    groups = [\n",
    "        # (start, end, race, gender, age)\n",
    "        (1, 8, 'asian', 'male', 'young'),\n",
    "        (9, 16, 'asian', 'male', 'elderly'),\n",
    "        (17, 24, 'asian', 'female', 'young'),\n",
    "        (25, 32, 'asian', 'female', 'elderly'),\n",
    "        (33, 40, 'caucasian', 'male', 'young'),\n",
    "        (41, 48, 'caucasian', 'male', 'elderly'),\n",
    "        (49, 56, 'caucasian', 'female', 'young'),\n",
    "        (57, 64, 'caucasian', 'female', 'elderly')\n",
    "    ]\n",
    "    \n",
    "    for group_start, group_end, race, gender, age in groups:\n",
    "        for img_num in range(group_start, group_end + 1):\n",
    "            # Determine expression: first half of group is neutral, second half is emotional\n",
    "            group_position = img_num - group_start + 1  # 1 to 8\n",
    "            expression = 'neutral' if group_position <= 4 else 'emotional'\n",
    "            \n",
    "            mapping[img_num] = {\n",
    "                'race': race,\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'expression': expression\n",
    "            }\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "def process_subject(subject, session='01', run='01'):\n",
    "    \"\"\"\n",
    "    Main preprocessing function for one subject\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PROCESSING SUBJECT {subject}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 1. LOAD DATA\n",
    "    # =========================================================================\n",
    "    print(f\"\\n1. Loading data...\")\n",
    "    \n",
    "    # Load MEG data\n",
    "    meg_path = f\"../data/ds005107/sub-{subject}/ses-{session}/meg/sub-{subject}_ses-{session}_task-face_run-{run}_meg.fif\"\n",
    "    if not os.path.exists(meg_path):\n",
    "        print(f\"‚ùå MEG file not found: {meg_path}\")\n",
    "        return None\n",
    "    \n",
    "    raw = mne.io.read_raw_fif(meg_path, preload=True, verbose=False)\n",
    "    print(f\"‚úì Loaded MEG data: {len(raw.ch_names)} channels, {raw.info['sfreq']} Hz\")\n",
    "    \n",
    "    # Load behavioral data\n",
    "    beh_path = f\"../data/ds005107/sub-{subject}/ses-{session}/beh/sub-{subject}_ses-{session}_task-face_run-{run}_events.tsv\"\n",
    "    beh_data = pd.read_csv(beh_path, sep='\\t')\n",
    "    print(f\"‚úì Loaded behavioral data: {len(beh_data)} trials\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 2. EXTRACT EVENTS\n",
    "    # =========================================================================\n",
    "    print(f\"\\n2. Extracting events...\")\n",
    "    \n",
    "    events = mne.find_events(raw, stim_channel='STIM', shortest_event=1, verbose=False)\n",
    "    print(f\"‚úì Found {len(events)} events in STIM channel\")\n",
    "    \n",
    "    # Filter for face presentation events (codes 1 and 55)\n",
    "    face_events = [ev for ev in events if ev[2] in [1, 55]]\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 3. CREATE EVENT LIST\n",
    "    # =========================================================================\n",
    "    print(f\"\\n3. Creating event list...\")\n",
    "    \n",
    "    stim_mapping = create_stimulus_mapping()\n",
    "    mne_events = []\n",
    "    event_info = []\n",
    "    \n",
    "    # Match behavioral trials to MEG events\n",
    "    for i in range(min(len(face_events), len(beh_data))):\n",
    "        sample, _, code = face_events[i]\n",
    "        row = beh_data.iloc[i]\n",
    "        \n",
    "        img_num = extract_image_number(row['stim_file'])\n",
    "        if img_num and img_num in stim_mapping:\n",
    "            dims = stim_mapping[img_num]\n",
    "            is_catch = (code == 55)\n",
    "            \n",
    "            # Event code: 1 for regular, 2 for catch\n",
    "            event_code = 2 if is_catch else 1\n",
    "            \n",
    "            mne_events.append([sample, 0, event_code])\n",
    "            event_info.append({\n",
    "                'sample': sample,\n",
    "                'event_code': event_code,\n",
    "                'image_num': img_num,\n",
    "                'is_catch': is_catch,\n",
    "                'race': dims['race'],\n",
    "                'gender': dims['gender'],\n",
    "                'age': dims['age'],\n",
    "                'expression': dims['expression']\n",
    "            })\n",
    "    \n",
    "    mne_events = np.array(mne_events)\n",
    "    print(f\"‚úì Created {len(mne_events)} MNE events\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 4. PREPROCESS MEG DATA\n",
    "    # =========================================================================\n",
    "    print(f\"\\n4. Preprocessing MEG data...\")\n",
    "    \n",
    "    # Keep only magnetometers\n",
    "    raw_mag = raw.copy().pick(picks='mag')\n",
    "    \n",
    "    # Apply filters (as in paper)\n",
    "    # Notch filters\n",
    "    notch_freqs = [44, 50, 100, 150, 200, 250]\n",
    "    for freq in notch_freqs:\n",
    "        raw_mag.notch_filter(freq, method='fir', phase='zero', verbose=False)\n",
    "    \n",
    "    # Bandpass filter\n",
    "    raw_mag.filter(1, 100, method='fir', phase='zero', verbose=False)\n",
    "    \n",
    "    # Detect bad channels\n",
    "    data = raw_mag.get_data()\n",
    "    variances = np.var(data, axis=1)\n",
    "    z_scores = np.abs(stats.zscore(variances))\n",
    "    bad_idx = np.where(z_scores > 3)[0]\n",
    "    bad_channels = [raw_mag.ch_names[i] for i in bad_idx]\n",
    "    \n",
    "    if bad_channels:\n",
    "        raw_mag.info['bads'] = bad_channels\n",
    "        print(f\"‚úì Marked bad channels: {bad_channels}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 5. CREATE EPOCHS\n",
    "    # =========================================================================\n",
    "    print(f\"\\n5. Creating epochs...\")\n",
    "    \n",
    "    event_dict = {'regular': 1, 'catch': 2}\n",
    "    \n",
    "    epochs = mne.Epochs(\n",
    "        raw_mag,\n",
    "        mne_events,\n",
    "        event_id=event_dict,\n",
    "        tmin=-0.2,\n",
    "        tmax=0.8,\n",
    "        baseline=(-0.2, 0),\n",
    "        preload=True,\n",
    "        reject=None,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    regular_epochs = epochs['regular']\n",
    "    catch_epochs = epochs['catch']\n",
    "    \n",
    "    print(f\"‚úì Created {len(epochs)} total epochs\")\n",
    "    print(f\"‚úì Regular trials: {len(regular_epochs)}\")\n",
    "    print(f\"‚úì Catch trials: {len(catch_epochs)}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 6. ORGANIZE BY DIMENSIONS\n",
    "    # =========================================================================\n",
    "    print(f\"\\n6. Organizing by face dimensions...\")\n",
    "    \n",
    "    dim_groups = {}\n",
    "    for dim_name in ['race', 'gender', 'age', 'expression']:\n",
    "        dim_groups[dim_name] = {}\n",
    "        \n",
    "        # Get unique values for this dimension\n",
    "        unique_vals = set([info[dim_name] for info in event_info if not info['is_catch']])\n",
    "        \n",
    "        for val in unique_vals:\n",
    "            # Find event indices for this value\n",
    "            event_indices = []\n",
    "            for i, info in enumerate(event_info):\n",
    "                if not info['is_catch'] and info[dim_name] == val:\n",
    "                    # Find corresponding epoch\n",
    "                    for j, ep_event in enumerate(regular_epochs.events):\n",
    "                        if ep_event[0] == info['sample']:\n",
    "                            event_indices.append(j)\n",
    "                            break\n",
    "            \n",
    "            if event_indices:\n",
    "                dim_epochs = regular_epochs[event_indices]\n",
    "                dim_groups[dim_name][val] = dim_epochs\n",
    "                print(f\"  {dim_name}={val}: {len(dim_epochs)} trials\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 7. SAVE DATA\n",
    "    # =========================================================================\n",
    "    print(f\"\\n7. Saving data...\")\n",
    "    \n",
    "    output_dir = f\"preprocessed/sub-{subject}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    base_name = f\"sub-{subject}_ses-{session}_run-{run}\"\n",
    "    \n",
    "    # Save with correct MNE naming conventions\n",
    "    raw_mag.save(f\"{output_dir}/{base_name}_raw.fif\", overwrite=True)\n",
    "    epochs.save(f\"{output_dir}/{base_name}_all-epo.fif\", overwrite=True)\n",
    "    regular_epochs.save(f\"{output_dir}/{base_name}_regular-epo.fif\", overwrite=True)\n",
    "    \n",
    "    # Save dimension groups\n",
    "    for dim_name, groups in dim_groups.items():\n",
    "        dim_dir = f\"{output_dir}/dimensions/{dim_name}\"\n",
    "        os.makedirs(dim_dir, exist_ok=True)\n",
    "        \n",
    "        for val, ep in groups.items():\n",
    "            ep.save(f\"{dim_dir}/{base_name}_{dim_name}_{val}-epo.fif\", overwrite=True)\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'subject': subject,\n",
    "        'session': session,\n",
    "        'run': run,\n",
    "        'total_epochs': len(epochs),\n",
    "        'regular_epochs': len(regular_epochs),\n",
    "        'catch_epochs': len(catch_epochs),\n",
    "        'bad_channels': bad_channels,\n",
    "        'sampling_rate': float(raw.info['sfreq']),  # Convert to Python float\n",
    "        'dimension_counts': {\n",
    "            dim_name: {val: len(ep) for val, ep in groups.items()}\n",
    "            for dim_name, groups in dim_groups.items()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Convert numpy types to Python types for JSON serialization\n",
    "    def convert_types(obj):\n",
    "        if isinstance(obj, (np.integer, np.int64, np.int32)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {k: convert_types(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [convert_types(item) for item in obj]\n",
    "        else:\n",
    "            return obj\n",
    "    \n",
    "    metadata = convert_types(metadata)\n",
    "    \n",
    "    with open(f\"{output_dir}/{base_name}_metadata.json\", 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"‚úì Saved all data to {output_dir}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 8. CREATE SUMMARY\n",
    "    # =========================================================================\n",
    "    print(f\"\\n8. Creating summary...\")\n",
    "    \n",
    "    print(f\"\\nüìä PREPROCESSING COMPLETE FOR SUBJECT {subject}\")\n",
    "    print(f\"   Output directory: {output_dir}\")\n",
    "    print(f\"   Regular trials: {len(regular_epochs)}\")\n",
    "    print(f\"   Dimension breakdown:\")\n",
    "    \n",
    "    for dim_name, groups in dim_groups.items():\n",
    "        print(f\"   {dim_name.upper()}:\")\n",
    "        for val, ep in groups.items():\n",
    "            print(f\"     {val}: {len(ep)} trials\")\n",
    "    \n",
    "    return {\n",
    "        'subject': subject,\n",
    "        'raw': raw_mag,\n",
    "        'epochs': epochs,\n",
    "        'regular_epochs': regular_epochs,\n",
    "        'dim_groups': dim_groups,\n",
    "        'output_dir': output_dir\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run preprocessing\"\"\"\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"OPM-MEG FACE PERCEPTION - PREPROCESSING\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Test with subject 01\n",
    "    print(f\"\\nTesting with subject 01...\")\n",
    "    results = process_subject('01')\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\n‚úÖ Successfully processed subject 01!\")\n",
    "        \n",
    "        # Ask about batch processing\n",
    "        response = input(\"\\nProcess all subjects? (y/n): \")\n",
    "        \n",
    "        if response.lower() == 'y':\n",
    "            # Process all subjects from the dataset\n",
    "            subjects = ['01', '02', '03', '04', '06', '07', '08', '09', '10',\n",
    "                       '11', '13', '14', '15', '16', '17', '18', '19', '20',\n",
    "                       '21', '22', '23']\n",
    "            \n",
    "            all_results = {}\n",
    "            for subject in subjects:\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"Processing subject {subject}...\")\n",
    "                try:\n",
    "                    result = process_subject(subject)\n",
    "                    if result:\n",
    "                        all_results[subject] = result\n",
    "                        print(f\"‚úì Done with subject {subject}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error with subject {subject}: {e}\")\n",
    "            \n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"BATCH PROCESSING COMPLETE\")\n",
    "            print(f\"{'='*80}\")\n",
    "            print(f\"Processed {len(all_results)} subjects successfully\")\n",
    "            print(f\"Data saved in: preprocessed/\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n‚è∏Ô∏è  Only processed subject 01\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"\\n‚ùå Failed to process subject 01\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f02f3b-d79d-49b5-8b73-36e9313a0d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
